import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# 2. Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print("--- Data Split Information ---")
print(f"Training set size: {X_train.shape[0]} samples")
print(f"Test set size: {X_test.shape[0]} samples")
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

# 3. Implement and train Classification Algorithms
print("\n--- Model Training ---")
logistic_model = LogisticRegression(max_iter=200)
knn_model = KNeighborsClassifier(n_neighbors=5)
decision_tree_model = DecisionTreeClassifier()

logistic_model.fit(X_train, y_train)
knn_model.fit(X_train, y_train)
decision_tree_model.fit(X_train, y_train)

print("All models trained successfully.")

# 4. Make Predictions and Evaluate Performance
print("\n--- Model Evaluation ---")

y_pred_logistic = logistic_model.predict(X_test)
y_pred_knn = knn_model.predict(X_test)
y_pred_decision_tree = decision_tree_model.predict(X_test)

accuracy_logistic = accuracy_score(y_test, y_pred_logistic)
accuracy_knn = accuracy_score(y_test, y_pred_knn)
accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)

print(f"Logistic Regression Accuracy: {accuracy_logistic * 100:.2f}%")
print(f"K-Nearest Neighbors Accuracy: {accuracy_knn * 100:.2f}%")
print(f"Decision Tree Classifier Accuracy: {accuracy_decision_tree * 100:.2f}%")

print("\n--- Classification Report for Logistic Regression ---")
print(classification_report(y_test, y_pred_logistic))

print("\n--- Classification Report for K-Nearest Neighbors (KNN) ---")
print(classification_report(y_test, y_pred_knn))

print("\n--- Classification Report for Decision Tree Classifier ---")
print(classification_report(y_test, y_pred_decision_tree))

# 5. Visualize Performance Comparison (Accuracy Bar Chart)
models = ['Logistic Regression', 'KNN', 'Decision Tree']
accuracies = [accuracy_logistic, accuracy_knn, accuracy_decision_tree]

plt.figure(figsize=(8, 6))
plt.bar(models, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])
plt.ylim(0.0, 1.0)
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')
plt.show()

# Visualize Confusion Matrices
cm_logistic = confusion_matrix(y_test, y_pred_logistic)
cm_knn = confusion_matrix(y_test, y_pred_knn)
cm_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)

fig, axes = plt.subplots(1, 3, figsize=(18, 5))
fig.suptitle('Confusion Matrices Comparison')

sns.heatmap(cm_logistic, annot=True, fmt="d", cmap="Blues",
            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axes[0])
axes[0].set_title('Logistic Regression')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(cm_knn, annot=True, fmt="d", cmap="Blues",
            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axes[1])
axes[1].set_title('K-Nearest Neighbors (KNN)')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

sns.heatmap(cm_decision_tree, annot=True, fmt="d", cmap="Blues",
            xticklabels=iris.target_names, yticklabels=iris.target_names, ax=axes[2])
axes[2].set_title('Decision Tree Classifier')
axes[2].set_xlabel('Predicted')
axes[2].set_ylabel('Actual')

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()
